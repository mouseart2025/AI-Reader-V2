# PRD 审阅报告：导入可靠性 + 文本卫生 + 质量框架升级

> 审阅基于：对现有代码库的全量扫描（chapter_splitter.py, text_processor.py, chapter_classifier.py, novel_service.py, UploadDialog.tsx 等 12 个核心文件）
> 审阅日期：2026-02-15

---

## 一、总体评价

PRD 抓住了正确的核心问题——**导入失败是最大的用户流失漏斗**。方向完全正确。但存在以下需要修订的问题：

### 1.1 低估了现有能力

PRD 多处描述暗示系统"几乎没有章节切分能力"，实际上现有基础设施已经相当完善：

| PRD 假设 | 实际现状 |
|---------|---------|
| "章节切分失败导致无法使用" | 已有 5 种切分模式 + 自动选择 + 自定义正则 + 前端实时预览 + 重新切分 |
| "缺少预览确认" | `UploadDialog.tsx` 已有完整的 5 阶段状态机：select → uploading → **preview** → duplicate → confirming |
| "用户无法修复" | 已有：切换模式按钮组 + 自定义正则输入 + 重新切分 + 章节排除复选框 |
| "缺少失败警告" | `novel_service.py` 已生成 4 类警告（仅 1 章、超大章、可疑章、大文件） |
| "缺少非正文过滤" | `chapter_classifier.py` 已有 6 条形态学规则 + 对话检测 |
| "缺少卷识别" | 已有显式卷标记检测 + 隐式章节编号重置检测 |

**核心缺口只有两个**：
1. **没有字数切分 fallback** — 当所有 5 种正则都匹配不到 ≥2 次时，直接返回"全文"单章，没有按字数切分的退化策略
2. **没有文本卫生检测/清理** — 完全缺失

### 1.2 范围过大，Phase 混乱

PRD 在"P0 必须补齐"中塞入了"分析版本管理 + Diff + 回滚"和"待审队列"——这两个是**全新的基础设施模块**，工程量远超导入改进，不应与导入捆绑在同一版本。把它们放到 P0 会导致交付周期无限延长。

### 1.3 "1500 本基准测试"定义得当但缺少具体 CLI 设计

批量测试工具的需求写得好，但缺少对现有 `split_chapters()` 函数的直接利用方案——实际上只需要一个 Python 脚本调用已有函数即可，不需要新建 CLI 框架。

---

## 二、逐模块评审

### 2.1 章节切分引擎 v2 (PRD §6.1.5-A)

**A1. 预处理** — 大部分已实现。

| 需求 | 现状 | 差距 |
|------|------|------|
| 统一换行 | ✅ `chapter_splitter.py:92` \r\n → \n | 无 |
| 去 BOM | ⚠️ 隐式依赖 Python codec | 需显式处理 UTF-8 BOM (3 行代码) |
| 统一空白字符 | ⚠️ 正则里 `\s*` 容忍了前导空白 | 可加全角空格→半角转换 |
| 段落规整 | ❌ 缺 | 需要：连续空行压缩、行首缩进统一 |

**A2. 多策略切分** — 已有 5 种，缺 1 种关键退化策略。

| PRD 要求的策略 | 现状 |
|---------------|------|
| 章节标题正则 | ✅ `chapter_zh` + `section_zh` |
| 英文标题 | ❌ 缺 CHAPTER/Part 等英文模式 |
| 启发式标题行 | ❌ 缺（短行 + 无标点 + 前后有空行的行识别为标题） |
| Fallback 按字数切分 | ❌ **核心缺口**。当前返回"全文"单章 |

**修订建议**：
- 新增策略 6：`chapter_en`（CHAPTER/Part/Prologue/Epilogue）
- 新增策略 7：`heuristic_title`（短行启发式）
- 新增策略 8：`fixed_size` fallback（按 ~8000 字切分，可配置）
- **不需要**"多策略并行评分"的复杂框架——当前"按匹配数选最多"的逻辑已经够用，只需在 0 匹配时加 fallback

**A3. 策略评分选择** — PRD 描述的评分函数过于复杂。

现有逻辑（`best_count = max(matches)`）简单有效。建议：
- 保持现有"最多匹配数"选择逻辑
- **仅在最佳结果仍不理想时**（例如仅 2-3 个匹配但文本很长），才触发 fallback
- 不需要实现完整的多维评分函数

**A4. 异常检测与解释** — 好需求，实现成本低。

现有 `novel_service.py` 已有 4 类警告，建议扩展为结构化标签：
```python
class SplitDiagnosis:
    tag: str        # NO_HEADING_MATCH / HEADING_TOO_SPARSE / SINGLE_HUGE_CHAPTER / ...
    message: str    # 面向用户的中文说明
    suggestion: str # 推荐操作
```
约 50 行代码。

**A5. 预览交互** — 已有 80% 能力。

| 功能 | 现状 |
|------|------|
| 切换策略即时更新 | ✅ 已有 |
| 自定义正则 | ✅ 已有 |
| 章节排除 | ✅ 已有 |
| 章节合并 | ❌ 缺 |
| 章节拆分 | ❌ 缺 |
| 章节重命名 | ❌ 缺 |

建议：合并/拆分/重命名列为 P1，不阻塞 P0。

### 2.2 文本卫生检查 (PRD §6.1.5-B)

**完全缺失，需要从零实现。PRD 描述合理。**

修订建议：

**B1. 检测分类** — 简化为 5 类高置信模式：
1. **URL/域名**：`https?://\S+`、`www\.\S+`、`\w+\.(com|cn|net|org)`
2. **推广导流**：关键词匹配（公众号、微信、QQ群、关注、搜索、下载APP、备用网址、书友群）
3. **站点模板句**：特征句式（"本书由.*整理"、"更多.*请访问"、"手机用户请到.*阅读"）
4. **分割线/装饰**：`^[-=*_#]{4,}$`、`^[※◆◇□■●○]{3,}$`
5. **重复尾注**：每章末尾相同的 N 行（跨 ≥50% 章节出现）

**B2. 清理模式** — 同意 PRD 的保守/激进分层，但建议：
- 默认只做**标记**（高亮显示），不自动删除
- 用户确认后才清理
- 保留原文在内存/缓存中（不需要持久化 original_text，因为用户可以重新上传）

**B3. 预览 Diff** — 简化实现：
- 不需要完整 diff 组件
- 显示"将删除 N 行，共 M 处匹配"+ 前 5 个匹配样例即可
- 用户点"清理并重新切分"

**B4. 规则管理** — P1 延后：
- P0 只做内置规则包
- 用户自定义和 Legado 导入列为 P2

### 2.3 基准测试工具 (PRD §6.1.5-C)

**好需求，实现简单。**

修订建议：

```python
# benchmark_import.py — 直接调用现有 split_chapters()
# 输入：目录路径
# 输出：CSV + 汇总 JSON
# 零 LLM 调用
```

核心就是一个 ~100 行的 Python 脚本：
1. 遍历目录下所有 .txt
2. 对每个文件：`decode_text()` → `split_chapters()` → 记录结果
3. 输出 CSV（文件名、编码、章节数、最大章字数、匹配模式、诊断标签）
4. 输出汇总（可用率、失败原因分布、top 20 失败样本）

不需要 CI 框架、HTML 报告、抽样诊断等复杂功能。跑一次改一次规则即可。

---

## 三、范围裁剪建议

### 应从本版本移除的需求

| 需求 | 原 PRD 位置 | 建议 | 原因 |
|------|------------|------|------|
| 分析版本管理 + Diff + 回滚 | §7.1.1 P0 | → Phase 2 | 全新基础设施，工程量 ≥ 导入改进总和 |
| 待审队列（Human-in-the-loop） | §7.1.2 P0 | → Phase 2 | 需要全新 UI + 后端状态机 |
| 分析档位封装（Fast/Balanced/Accurate） | §7.1.3 P0 | → Phase 2 | 需要多模型对比框架 |
| 一致性审计工作台 | §7.2.5 P1 | → Phase 3 | 需要全新的冲突检测引擎 |
| Series Bible 导出中心 | §7.2.6 P1 | 保留但独立为下个版本 | 与导入无关 |
| 统一引用系统 | §7.2.7 P1 | → Phase 2 | 跨模块基础设施改造 |
| 批量导入 + 批量报告 | §6.1.3 | → P2 | 先做好单本 |
| 高级净化规则包 + Legado | §6.1.3 | → P2 | 先做好内置规则 |

### 应保留的核心范围（本版本）

1. **章节切分 fallback**（字数切分 + 英文标题 + 启发式标题）
2. **切分诊断标签**（结构化失败原因 + 推荐操作）
3. **文本卫生检测与清理**（5 类模式 + 标记预览 + 确认清理）
4. **1500 本基准测试脚本**（CSV 输出 + 汇总统计）
5. **预处理增强**（BOM、全角空格、连续空行压缩）

---

## 四、修订后的里程碑

### Milestone 1：章节切分永不失败

**目标**：1500 本基准集可用率 ≥ 95%

| Story | 描述 | 工作量 |
|-------|------|--------|
| S1 | 基准测试脚本：遍历目录 → CSV + 汇总 JSON | 小 |
| S2 | 跑首次基准，建立 baseline，归类失败原因 | 小 |
| S3 | 预处理增强：BOM 去除、全角空格、连续空行压缩 | 小 |
| S4 | 新增 `chapter_en` 模式（CHAPTER/Part/Prologue） | 小 |
| S5 | 新增 `heuristic_title` 模式（短行启发式标题检测） | 中 |
| S6 | 新增 `fixed_size` fallback（当所有模式 < 2 匹配时，按字数切分） | 小 |
| S7 | 切分诊断标签：结构化 `SplitDiagnosis` + 失败原因 + 推荐操作 | 小 |
| S8 | 前端：诊断信息展示 + "一键按字数切分"按钮 | 小 |
| S9 | 跑第二次基准，验证可用率达标，对比 diff | 小 |

### Milestone 2：文本卫生检测与清理

**目标**：杂质检测命中率合理，清理可预览可撤销

| Story | 描述 | 工作量 |
|-------|------|--------|
| S10 | 后端：`text_sanitizer.py` — 5 类杂质检测 + 标记 + 清理 | 中 |
| S11 | 后端：重复尾注检测（跨章节比对末尾 N 行） | 中 |
| S12 | 后端：`parse_upload()` 集成卫生检测，返回 `hygiene_report` | 小 |
| S13 | 前端：卫生报告展示（匹配数 + 样例预览 + "清理并重新切分"按钮） | 中 |
| S14 | 后端：清理后重新切分 pipeline（净化 → 切分 → 预览更新） | 小 |
| S15 | 基准测试增加卫生检测列（杂质行数、类型分布） | 小 |

### Milestone 3（可选）：预览增强

| Story | 描述 | 工作量 |
|-------|------|--------|
| S16 | 前端：章节合并操作（选中多章 → 合并为一章） | 中 |
| S17 | 前端：章节重命名（点击标题可编辑） | 小 |
| S18 | 后端/前端：编码异常检测与警告 | 小 |

---

## 五、对其他模块需求的评审意见

PRD §6.2-6.8 对分析、阅读、问答、地图、百科、时间线、关系图模块的"底线/可收费/指标"定义**写得很好**，可以直接作为长期产品质量标准文档保留。但这些不应纳入本版本的开发范围——它们是**质量框架文档**而非**版本需求**。

建议：
- 将 §6.2-6.8 保存为独立的 `quality-framework.md`，作为持续参考
- 本版本 PRD 只聚焦 §6.1（导入模块）

---

## 六、技术方案修订

### 6.1 章节切分改动（基于现有 `chapter_splitter.py`）

```
现有流程：
  5 种正则模式 → 选匹配最多的 → 无匹配则返回"全文"

修订后流程：
  预处理（BOM/空白/空行） →
  7 种正则模式（+chapter_en, +heuristic_title） →
  选匹配最多的 →
  若无匹配 OR 仅 1 章且 > 30k 字 →
    fixed_size fallback（按 ~8000 字切分） →
  输出 chapters + SplitDiagnosis
```

改动集中在 `chapter_splitter.py`（新增 ~120 行）和 `novel_service.py`（诊断逻辑 ~30 行）。

### 6.2 文本卫生（新增 `text_sanitizer.py`）

```python
# backend/src/utils/text_sanitizer.py

class HygieneReport:
    total_suspect_lines: int
    categories: dict[str, list[SuspectLine]]  # url/promo/template/separator/repeated
    sample_lines: list[str]  # 前 10 个样例

def detect_noise(text: str) -> HygieneReport: ...
def clean_text(text: str, report: HygieneReport, mode: str = "conservative") -> str: ...
```

~200 行。纯正则/字符串操作，不调用 LLM。

### 6.3 基准测试脚本

```python
# backend/scripts/benchmark_import.py
# 直接调用 split_chapters() + detect_noise()
# 输出 CSV: filename, encoding, chapters, max_ch_words, mode, diagnosis, noise_lines
# 输出 summary.json: usable_rate, failure_distribution, top_failures
```

~100 行。

---

## 七、成功标准修订

| 指标 | 原 PRD | 修订 | 理由 |
|------|--------|------|------|
| 基准集可用率 | ≥ 95% | ≥ 90%（首轮），≥ 95%（迭代后） | 首轮可能有意外格式，留迭代空间 |
| 仅 1 章超大章比例 | ≤ 2% | ≤ 5%（首轮），≤ 2%（迭代后） | 同上 |
| 杂质清理采用率 | ≥ 30% | 不设硬指标 | 取决于基准集中杂质比例，不可控 |
| 误杀撤销率 | ≤ 5% | ≤ 10% | 保守模式下误杀率本身很低，但分母小时百分比波动大 |

---

## 八、风险补充

| 风险 | PRD 已提及 | 补充 |
|------|-----------|------|
| 启发式标题误判正文 | ✅ | `heuristic_title` 模式需要严格约束：行长 ≤ 30 字、前后有空行、不含标点 |
| 按字数切分破坏段落 | ❌ | fallback 应在段落边界切分，不可在句中截断 |
| GB18030 文件 BOM 处理 | ❌ | GB18030 没有标准 BOM，但有些工具会加 `\xff\xfe`，需处理 |
| 基准集本身质量不均 | ❌ | 1500 本 TXT 可能包含非小说文本（诗集、散文集），需先人工抽样分类 |

---

## 九、总结

**PRD 的核心方向正确**，但需要：
1. **认识到现有基础已相当完善**，核心缺口只有 fallback 和卫生检测
2. **大幅裁剪范围**，移除分析版本管理/待审队列/审计工作台
3. **聚焦 2 个 Milestone**：切分永不失败 + 文本卫生
4. **降低首轮指标预期**，留迭代空间

预估工作量：**Milestone 1（9 Stories） + Milestone 2（6 Stories） = 15 Stories**，远小于原 PRD 暗示的 30+ Stories。
